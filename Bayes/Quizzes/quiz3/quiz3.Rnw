\documentclass{article}

\usepackage{fancyhdr} % Required for custom headers
\usepackage{lastpage} % Required to determine the last page for the footer
\usepackage{extramarks} % Required for headers and footers
\usepackage{graphicx} % Required to insert images
\usepackage{hyperref}
\usepackage{amsmath} %for binomial pdf
\usepackage{parskip} % so that there's space bw paragraphs
\usepackage{float}
\usepackage{amsfonts}

% Margins
\topmargin=-0.45in
\evensidemargin=0in
\oddsidemargin=0in
\textwidth=6.5in
\textheight=9.0in
\headsep=0.25in 

\linespread{1.1} % Line spacing

% Set up the header and footer
\pagestyle{fancy}
\lhead{STAT 532: Bayes} % Top left header
\chead{Quiz 3} % Top center header
\rhead{Andrea Mack\\ Tan Tran\\ Moses Obiri} % Top right header
\lfoot{10/05/2016} % Bottom left footer
\cfoot{} % Bottom center footer
\rfoot{Page\ \thepage\ of\ \pageref{LastPage}} % Bottom right footer
\renewcommand\headrulewidth{0.4pt} % Size of the header rule
\renewcommand\footrulewidth{0.4pt} % Size of the footer rule

\setlength\parindent{0pt} % Removes all indentation from paragraphs
\setlength\parskip{0.5cm}
\restylefloat{table}

%----------------------------------------------------------------------------------------
%	DOCUMENT STRUCTURE COMMANDS
%	Skip this unless you know what you're doing
%----------------------------------------------------------------------------------------

% Header and footer for when a page split occurs within a problem environment
\newcommand{\enterProblemHeader}[1]{
\nobreak\extramarks{#1}{#1 continued on next page\ldots}\nobreak
\nobreak\extramarks{#1 (continued)}{#1 continued on next page\ldots}\nobreak
}

% Header and footer for when a page split occurs between problem environments
\newcommand{\exitProblemHeader}[1]{
\nobreak\extramarks{#1 (continued)}{#1 continued on next page\ldots}\nobreak
\nobreak\extramarks{#1}{}\nobreak
}


%----------------------------------------------------------------------------------------%

\begin{document}
<<setup, include = FALSE>>=
require(xtable)
require(ggplot2)
require(dplyr) #between()
require(truncnorm) #work with truncated norm
require(LearnBayes)
opts_chunk$set(echo = FALSE, warning = FALSE)
@

\begin{enumerate}
\item%1 

<<prob1>>=
require(LearnBayes)
require(truncnorm)
delta <- c(1,2,3)
prob.delta <- c(0.45,0.1,0.45)

delta.out <- sample(delta,1000,replace = TRUE, prob=prob.delta)
mu <- c(-3,0,3)

#if mu[delta.out] = length(n) = 1000, then for each element in mu[delta.out] will draw randomly from the
#specified mu[delta.out], if not, it will recycle through
theta.out <- rnorm(1000, mu[delta.out], sd = sqrt(1/3))

hist(theta.out, probability = TRUE, ylim = c(0,1), breaks = 100, main = "MC estimated PDF", xlab = "Posterior of theta")
lines(x = seq(-5,5, by = 0.01), 0.45*dnorm(seq(-5,5, by = 0.01),mu[1], sd = sqrt(1/3)) + 
        0.1*dnorm(seq(-5,5, by = 0.01),mu[2], sd = sqrt(1/3)) +
  0.45*dnorm(seq(-5,5, by = 0.01),mu[3], sd = sqrt(1/3)), col = "red")

@

\item %2

<<prob2, results = 'asis', fig.height=4, fig.width=4>>=
theta0 <- 0

prob_delta0 <- prob.delta[1]

fn.d <- function(t,d){
  pr.d <- prob.delta[d]
  pr.thet_d <- dnorm(t,mu[d], sqrt(1/3))
  pr.d*pr.thet_d
}
#delta.sub <- delta[-which(delta == delta0)]

den0 <- NULL
for(i in 1: length(delta)){
  den0[i] <- fn.d(theta0, delta[i])
}

denom.out <- sum(den0)
pdf.out <- den0/denom.out

#check
#pdf.out
#sum(pdf.out)

delta.new <- sample(delta, 1, replace = TRUE, prob = pdf.out)
theta.new <- rnorm(1, mu[delta.new], sd = sqrt(1/3))

#--------#######---------#
  # Iterate many times #
#--------#######---------#

delta.finish100 <- c(rep(0,100))
theta.finish100 <- c(rep(0,100))

delta.finish100[1] <- delta.new
theta.finish100[1] <- theta0

for(i in 2:100){
  fn.d <- function(t,d){
  pr.d <- prob.delta[d]
  pr.thet_d <- dnorm(t,mu[d], sqrt(1/3))
  pr.d*pr.thet_d
}
#delta.sub[i] <- delta[-which(delta == delta.finish100[i])]

den0 <- data.frame(matrix(rep(0,3*100), nrow = 100, ncol = 3, byrow = TRUE))
pdf.out <- data.frame(matrix(rep(0,3*100), nrow = 100, ncol = 3, byrow = TRUE))

den0[i,] <- fn.d(theta.finish100[i], delta)

denom.out <- c(rep(0,100))
denom.out[i] <- sum(den0[i,])
pdf.out[i,] <- den0[i,]/denom.out[i]


delta.finish100[i+1] <- sample(delta, 1, replace = TRUE, prob = pdf.out[i,])
theta.finish100[i+1] <- rnorm(1, mu[delta.finish100[i+1]], sd = sqrt(1/3))

}

hist(theta.finish100, probability = TRUE, xlim=c(-4,4), ylim = c(0,0.5), breaks = 100, main = "GIBBS approximate PDF \n 100 sims", xlab = "Full conditional \n posterior of expression(theta)")
lines(x = seq(-5,5, by = 0.01), 0.45*dnorm(seq(-5,5, by = 0.01),mu[1], sd = sqrt(1/3)) + 
        0.1*dnorm(seq(-5,5, by = 0.01),mu[2], sd = sqrt(1/3)) +
  0.45*dnorm(seq(-5,5, by = 0.01),mu[3], sd = sqrt(1/3)), col = "red")

index <- c(seq(1:100))

par(mfrow=c(1,1))
plot(index, theta.finish100[1:100], ylab = expression(theta), main = "Trace of expression(paste(theta)) \n after 100 iterations")
lines(y = theta.finish100[1:100], x = index, col = "red")
@

The trace plot shows that mixing begins after about 20 simulations, but does not include the part of the distribution centered at -3, also shown in the histogram.

<<prob2e4, results = 'asis', fig.height=4, fig.width=4>>=
theta0 <- 0

prob_delta0 <- prob.delta[1]

fn.d <- function(t,d){
  pr.d <- prob.delta[d]
  pr.thet_d <- dnorm(t,mu[d], sqrt(1/3))
  pr.d*pr.thet_d
}
#delta.sub <- delta[-which(delta == delta0)]

den0 <- NULL
for(i in 1: length(delta)){
  den0[i] <- fn.d(theta0, delta[i])
}

denom.out <- sum(den0)
pdf.out <- den0/denom.out

#check
#pdf.out
#sum(pdf.out)

delta.new <- sample(delta, 1, replace = TRUE, prob = pdf.out)
theta.new <- rnorm(1, mu[delta.new], sd = sqrt(1/3))

#--------#######---------#
  # Iterate many times #
#--------#######---------#

delta.finish100 <- c(rep(0,1000))
theta.finish100 <- c(rep(0,1000))

delta.finish100[1] <- delta.new
theta.finish100[1] <- theta0

for(i in 2:1000){
  fn.d <- function(t,d){
  pr.d <- prob.delta[d]
  pr.thet_d <- dnorm(t,mu[d], sqrt(1/3))
  pr.d*pr.thet_d
}
#delta.sub[i] <- delta[-which(delta == delta.finish100[i])]

den0 <- data.frame(matrix(rep(0,3*1000), nrow = 1000, ncol = 3, byrow = TRUE))
pdf.out <- data.frame(matrix(rep(0,3*1000), nrow = 1000, ncol = 3, byrow = TRUE))

den0[i,] <- fn.d(theta.finish100[i], delta)

denom.out <- c(rep(0,1000))
denom.out[i] <- sum(den0[i,])
pdf.out[i,] <- den0[i,]/denom.out[i]


delta.finish100[i+1] <- sample(delta, 1, replace = TRUE, prob = pdf.out[i,])
theta.finish100[i+1] <- rnorm(1, mu[delta.finish100[i+1]], sd = sqrt(1/3))

}

hist(theta.finish100, probability = TRUE, xlim=c(-4,4), ylim = c(0,1), breaks = 1000, main = "GIBBS approximate PDF \n 1000 sims", xlab = "Full conditional \n posterior of expression(theta)")
lines(x = seq(-5,5, by = 0.01), 0.45*dnorm(seq(-5,5, by = 0.01),mu[1], sd = sqrt(1/3)) + 
        0.1*dnorm(seq(-5,5, by = 0.01),mu[2], sd = sqrt(1/3)) +
  0.45*dnorm(seq(-5,5, by = 0.01),mu[3], sd = sqrt(1/3)), col = "red")

index <- c(seq(1:1000))

par(mfrow=c(1,1))
plot(index, theta.finish100[1:1000], ylab = expression(theta), main = "Trace of expression(paste(theta)) \n after 1000 iterations")
lines(y = theta.finish100[1:1000], x = index, col = "red")

@

In the trace plot and histogram show most the observations around -3. With the larger number of simulations we would have hoped for more mixing.

<<prob2e5, results = 'asis', fig.height=4, fig.width=4>>=
theta0 <- 0

prob_delta0 <- prob.delta[1]

fn.d <- function(t,d){
  pr.d <- prob.delta[d]
  pr.thet_d <- dnorm(t,mu[d], sqrt(1/3))
  pr.d*pr.thet_d
}
#delta.sub <- delta[-which(delta == delta0)]

den0 <- NULL
for(i in 1: length(delta)){
  den0[i] <- fn.d(theta0, delta[i])
}

denom.out <- sum(den0)
pdf.out <- den0/denom.out

#check
#pdf.out
#sum(pdf.out)

delta.new <- sample(delta, 1, replace = TRUE, prob = pdf.out)
theta.new <- rnorm(1, mu[delta.new], sd = sqrt(1/3))

#--------#######---------#
  # Iterate many times #
#--------#######---------#

delta.finish100 <- c(rep(0,10000))
theta.finish100 <- c(rep(0,10000))

delta.finish100[1] <- delta.new
theta.finish100[1] <- theta0

for(i in 2:10000){
  fn.d <- function(t,d){
  pr.d <- prob.delta[d]
  pr.thet_d <- dnorm(t,mu[d], sqrt(1/3))
  pr.d*pr.thet_d
}
#delta.sub[i] <- delta[-which(delta == delta.finish100[i])]

den0 <- data.frame(matrix(rep(0,3*10000), nrow = 10000, ncol = 3, byrow = TRUE))
pdf.out <- data.frame(matrix(rep(0,3*10000), nrow = 10000, ncol = 3, byrow = TRUE))

den0[i,] <- fn.d(theta.finish100[i], delta)

denom.out <- c(rep(0,10000))
denom.out[i] <- sum(den0[i,])
pdf.out[i,] <- den0[i,]/denom.out[i]


delta.finish100[i+1] <- sample(delta, 1, replace = TRUE, prob = pdf.out[i,])
theta.finish100[i+1] <- rnorm(1, mu[delta.finish100[i+1]], sd = sqrt(1/3))

}

hist(theta.finish100, probability = TRUE, xlim=c(-4,4), ylim = c(0,1), breaks = 10000, main = "GIBBS approximate PDF \n 10000 sims", xlab = "Full conditional \n posterior of expression(theta)")
lines(x = seq(-5,5, by = 0.01), 0.45*dnorm(seq(-5,5, by = 0.01),mu[1], sd = sqrt(1/3)) + 
        0.1*dnorm(seq(-5,5, by = 0.01),mu[2], sd = sqrt(1/3)) +
  0.45*dnorm(seq(-5,5, by = 0.01),mu[3], sd = sqrt(1/3)), col = "red")

index <- c(seq(1:10000))

par(mfrow=c(1,1))
plot(index, theta.finish100[1:10000], ylab = expression(theta), main = "Trace of expression(theta) \n after 10000 iterations")
lines(y = theta.finish100[1:10000], x = index, col = "red")

@

After 10000 simulations, the approximation appears to have converged, however the right portion of the plot still appears to be over sampled. Two thoughts: 

1) Is there a reason why the -3 region is always over sampled in each of these?

2) Could running more simulations may take us back out of convergence?


\item %3

Now the starting value for $\theta$ will be 100.

<<prob3, results = 'asis', fig.height=4, fig.width=4>>=
theta0 <- 100

prob_delta0 <- prob.delta[1]

fn.d <- function(t,d){
  pr.d <- prob.delta[d]
  pr.thet_d <- dnorm(t,mu[d], sqrt(1/3))
  pr.d*pr.thet_d
}

den0 <- NULL
for(i in 1: length(delta)){
  den0[i] <- fn.d(theta0, delta[i])
}

denom.out <- sum(den0)
pdf.out <- den0/denom.out

#check
#pdf.out
#sum(pdf.out)

delta.new <- sample(delta, 1, replace = TRUE, prob = pdf.out)
theta.new <- rnorm(1, mu[delta.new], sd = sqrt(1/3))

#--------#######---------#
  # Iterate many times #
#--------#######---------#

delta.finish100 <- c(rep(0,100))
theta.finish100 <- c(rep(0,100))

delta.finish100[1] <- delta.new
theta.finish100[1] <- theta0

for(i in 2:100){
  fn.d <- function(t,d){
  pr.d <- prob.delta[d]
  pr.thet_d <- dnorm(t,mu[d], sqrt(1/3))
  pr.d*pr.thet_d
}

den0 <- data.frame(matrix(rep(0,3*100), nrow = 100, ncol = 3, byrow = TRUE))
pdf.out <- data.frame(matrix(rep(0,3*100), nrow = 100, ncol = 3, byrow = TRUE))

den0[i,] <- fn.d(theta.finish100[i], delta)

denom.out <- c(rep(0,100))
denom.out[i] <- sum(den0[i,])
pdf.out[i,] <- den0[i,]/denom.out[i]


delta.finish100[i+1] <- sample(delta, 1, replace = TRUE, prob = pdf.out[i,])
theta.finish100[i+1] <- rnorm(1, mu[delta.finish100[i+1]], sd = sqrt(1/3))

}

hist(theta.finish100, probability = TRUE, xlim=c(-4,4), ylim = c(0,0.5), breaks = 100, main = "GIBBS approximate PDF \n 100 sims", xlab = "Full conditional \n posterior of expression(theta)")
lines(x = seq(-5,5, by = 0.01), 0.45*dnorm(seq(-5,5, by = 0.01),mu[1], sd = sqrt(1/3)) + 
        0.1*dnorm(seq(-5,5, by = 0.01),mu[2], sd = sqrt(1/3)) +
  0.45*dnorm(seq(-5,5, by = 0.01),mu[3], sd = sqrt(1/3)), col = "red")

index <- c(seq(1:100))

par(mfrow=c(1,1))
plot(index, theta.finish100[1:100], ylab = expression(theta), main = "Trace of expression(theta) \n after 100 iterations \n expression(theta0)  = 100")
lines(y = theta.finish100[1:100], x = index, col = "red")

@

In 100 simulations, the -3 region of approximationss do not appear enough. The trace plot shows most of the approximations occur in a string, with values close to -3. Mixing first occurs after about 20 simulations. I did get an error about NA being in the probability vector. From the in class discussion, it seems that this appears because most of the mass of the distribution is below 5, the probability of $\theta$ being 100 is essentially 0, so when that is used to simulate the next value of $\sigma^2$, we are essentially dividing by 0, which results in the NA.



<<prob3e4, results = 'asis', fig.height=4, fig.width=4>>=
theta0 <- 100

prob_delta0 <- prob.delta[1]

fn.d <- function(t,d){
  pr.d <- prob.delta[d]
  pr.thet_d <- dnorm(t,mu[d], sqrt(1/3))
  pr.d*pr.thet_d
}
#delta.sub <- delta[-which(delta == delta0)]

den0 <- NULL
for(i in 1: length(delta)){
  den0[i] <- fn.d(theta0, delta[i])
}

denom.out <- sum(den0)
pdf.out <- den0/denom.out

delta.new <- sample(delta, 1, replace = TRUE, prob = pdf.out)
theta.new <- rnorm(1, mu[delta.new], sd = sqrt(1/3))

#--------#######---------#
  # Iterate many times #
#--------#######---------#

delta.finish100 <- c(rep(0,1000))
theta.finish100 <- c(rep(0,1000))

delta.finish100[1] <- delta.new
theta.finish100[1] <- theta0

for(i in 2:1000){
  fn.d <- function(t,d){
  pr.d <- prob.delta[d]
  pr.thet_d <- dnorm(t,mu[d], sqrt(1/3))
  pr.d*pr.thet_d
}

den0 <- data.frame(matrix(rep(0,3*1000), nrow = 1000, ncol = 3, byrow = TRUE))
pdf.out <- data.frame(matrix(rep(0,3*1000), nrow = 1000, ncol = 3, byrow = TRUE))

den0[i,] <- fn.d(theta.finish100[i], delta)

denom.out <- c(rep(0,1000))
denom.out[i] <- sum(den0[i,])
pdf.out[i,] <- den0[i,]/denom.out[i]


delta.finish100[i+1] <- sample(delta, 1, replace = TRUE, prob = pdf.out[i,])
theta.finish100[i+1] <- rnorm(1, mu[delta.finish100[i+1]], sd = sqrt(1/3))

}

hist(theta.finish100, probability = TRUE, xlim=c(-4,4), ylim = c(0,1), breaks = 1000, main = "GIBBS approximate PDF \n 1000 sims", xlab = "Full conditional \n posterior of expression(theta)")
lines(x = seq(-5,5, by = 0.01), 0.45*dnorm(seq(-5,5, by = 0.01),mu[1], sd = sqrt(1/3)) + 
        0.1*dnorm(seq(-5,5, by = 0.01),mu[2], sd = sqrt(1/3)) +
  0.45*dnorm(seq(-5,5, by = 0.01),mu[3], sd = sqrt(1/3)), col = "red")

index <- c(seq(1:1000))

par(mfrow=c(1,1))
plot(index, theta.finish100[1:1000], ylab = expression(theta), main = "Trace of expression(theta) \n after 1000 iterations")
lines(y = theta.finish100[1:1000], x = index, col = "red")


@

There is little mixing even with 1000 simulations and more are needed for convergence.

<<prob3e5, results = 'asis', fig.height=4, fig.width=4>>=
theta0 <- 100

prob_delta0 <- prob.delta[1]

fn.d <- function(t,d){
  pr.d <- prob.delta[d]
  pr.thet_d <- dnorm(t,mu[d], sqrt(1/3))
  pr.d*pr.thet_d
}
#delta.sub <- delta[-which(delta == delta0)]

den0 <- NULL
for(i in 1: length(delta)){
  den0[i] <- fn.d(theta0, delta[i])
}

denom.out <- sum(den0)
pdf.out <- den0/denom.out

#check
#pdf.out
#sum(pdf.out)

delta.new <- sample(delta, 1, replace = TRUE, prob = pdf.out)
theta.new <- rnorm(1, mu[delta.new], sd = sqrt(1/3))

#--------#######---------#
  # Iterate many times #
#--------#######---------#

delta.finish100 <- c(rep(0,10000))
theta.finish100 <- c(rep(0,10000))

delta.finish100[1] <- delta.new
theta.finish100[1] <- theta0

for(i in 2:10000){
  fn.d <- function(t,d){
  pr.d <- prob.delta[d]
  pr.thet_d <- dnorm(t,mu[d], sqrt(1/3))
  pr.d*pr.thet_d
}
#delta.sub[i] <- delta[-which(delta == delta.finish100[i])]

den0 <- data.frame(matrix(rep(0,3*10000), nrow = 10000, ncol = 3, byrow = TRUE))
pdf.out <- data.frame(matrix(rep(0,3*10000), nrow = 10000, ncol = 3, byrow = TRUE))

den0[i,] <- fn.d(theta.finish100[i], delta)

denom.out <- c(rep(0,10000))
denom.out[i] <- sum(den0[i,])
pdf.out[i,] <- den0[i,]/denom.out[i]


delta.finish100[i+1] <- sample(delta, 1, replace = TRUE, prob = pdf.out[i,])
theta.finish100[i+1] <- rnorm(1, mu[delta.finish100[i+1]], sd = sqrt(1/3))

}

hist(theta.finish100, probability = TRUE, xlim=c(-4,4), ylim = c(0,1), breaks = 10000, main = "GIBBS approximate PDF \n 10000 sims", xlab = "Full conditional \n posterior of expression(theta)")
lines(x = seq(-5,5, by = 0.01), 0.45*dnorm(seq(-5,5, by = 0.01),mu[1], sd = sqrt(1/3)) + 
        0.1*dnorm(seq(-5,5, by = 0.01),mu[2], sd = sqrt(1/3)) +
  0.45*dnorm(seq(-5,5, by = 0.01),mu[3], sd = sqrt(1/3)), col = "red")

index <- c(seq(1:10000))

par(mfrow=c(1,1))
plot(index, theta.finish100[1:10000], ylab = expression(theta), main = "Trace of expression(theta) \n after 10000 iterations")
lines(y = theta.finish100[1:10000], x = index, col = "red")


@

The trace plot for 10000 simulations here is interesting because a nice pattern in the approximated $\theta$'s doesn't appear until 4000 simulations, but then is fairly consistent up to 10000 simulations. Again, it would be interesting to know whether this is a property of Gibbs samplers, or whether the pattern eventually could break if we did enough simulations. 

It is nice that, in #3 compared to #2, it didn't matter that the starting value for $\theta$ was extremely large, it only took one simulation for it to be down in the expected range.

Comparing #2 and #3 after 10000 simulations, there appears to be more approximations in the -3 in #2 and more approximations in the 3 range in #3. I'm not sure if that is by chance or can be explained.

The chains with $\theta_{o}$ = 0 appear to be shorter than with $\theta_{o}$ = 100, which is most apparent in the 10000 simulations of each.



\end{enumerate}

\end{document}
